{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import edward as ed\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import pickle\n",
    "import six\n",
    "import tensorflow as tf\n",
    "\n",
    "from edward.models import (\n",
    "    Dirichlet, Categorical, Empirical, ParamMixture)\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_mimic_data(data_dir):\n",
    "    \"\"\"Loads a dataset extracted from the MIMIC-III critical care database.\n",
    "    \n",
    "    Args:\n",
    "        None\n",
    "        \n",
    "    Returns:\n",
    "        w - List of lists of 1D NumPy arrays containing\n",
    "            tokens for each individual and data source.\n",
    "        dicts - List of token id to token dictionaries for \n",
    "                all data types\n",
    "    \"\"\"\n",
    "    \n",
    "    data_types = ['note', 'lab', 'med']\n",
    "\n",
    "    D = 50  # number of patients\n",
    "    S = len(data_types)  # number of data types\n",
    "\n",
    "    dicts = [None] * S\n",
    "    w = [[None] * S for d in range(D)]\n",
    "    z = [[None] * S for d in range(D)]\n",
    "    for s, dt in enumerate(data_types):\n",
    "        dict_file = os.path.join(data_dir,\n",
    "                                 'dicts',\n",
    "                                 dt + '_dict.p')\n",
    "\n",
    "        form_corpus_file = os.path.join(data_dir, \n",
    "                                        'form_corpora',\n",
    "                                        dt + '_form_corpus.txt')\n",
    "        \n",
    "        with open(dict_file, 'rb') as file:\n",
    "            dicts[s] = pickle.load(file)\n",
    "            \n",
    "\n",
    "        with open(form_corpus_file, 'r') as file:\n",
    "            for d, line in enumerate(file):\n",
    "                doc_tokenids = []\n",
    "                tokenid_counts = line.split(' ')[1:]\n",
    "\n",
    "                for tic in tokenid_counts:\n",
    "                    ti_c = tic.strip().split(':')\n",
    "                    tokenid = float(ti_c[0])\n",
    "                    count = int(ti_c[1])\n",
    "                    \n",
    "                    if count == 1:\n",
    "                        count += 1\n",
    "\n",
    "                    for _ in range(count):\n",
    "                        doc_tokenids.append(tokenid)\n",
    "\n",
    "                w[d][s] = np.array(doc_tokenids)\n",
    "    \n",
    "    return w, dicts, D, S\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############\n",
    "# DATA\n",
    "###############\n",
    "\n",
    "# Get MIMIC data\n",
    "w_train, dicts, D, S= load_mimic_data('../data')\n",
    "\n",
    "# Calculate vocabulary size for each data type\n",
    "V = [None] * S\n",
    "for s in range(S):\n",
    "    V[s] = len(dicts[s])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############\n",
    "# MODEL\n",
    "###############\n",
    "K = 5\n",
    "\n",
    "alpha = tf.ones(K) * 0.01\n",
    "\n",
    "beta, phi = [None] * S, [None] * S\n",
    "for s in range(S):\n",
    "    beta[s] = tf.ones(V[s]) * 0.01\n",
    "    phi[s] = Dirichlet(concentration=beta[s], \n",
    "                     sample_shape=K)\n",
    "\n",
    "theta = [None] * D\n",
    "w = [[None] * S for d in range(D)]\n",
    "z = [[None] * S for d in range(D)]\n",
    "for d in range(D):\n",
    "    theta[d] = Dirichlet(concentration=alpha)\n",
    "    \n",
    "    for s in range(S):\n",
    "\n",
    "        w[d][s] = ParamMixture(mixing_weights=theta[d], \n",
    "                            component_params={'probs': phi[s]},\n",
    "                            component_dist=Categorical,\n",
    "                            sample_shape=len(w_train[d][s]),\n",
    "                            validate_args=True)\n",
    "\n",
    "        z[d][s] = w[d][s].cat\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "####################\n",
    "#INFERENCE\n",
    "####################\n",
    "\n",
    "overall_time = time.time()\n",
    "\n",
    "# Data vars\n",
    "data_dict = {}\n",
    "for d in range(D):\n",
    "    for s in range(S):\n",
    "        data_dict[w[d][s]] = w_train[d][s]\n",
    "\n",
    "\n",
    "# Latent vars\n",
    "latent_vars_dict = {}\n",
    "\n",
    "T = 1000 # number of samples\n",
    "qphi = [None] * S\n",
    "for s in range(S):\n",
    "    print('Building latents for phi {} of {}'.format(s + 1, S))\n",
    "    qphi[s] = Empirical(tf.Variable(tf.zeros([T, K, V[s]])))\n",
    "    latent_vars_dict[phi[s]] = qphi[s]\n",
    "\n",
    "qtheta = [None] * D\n",
    "qz = [[None] * S for d in range(D)]\n",
    "for d in range(D):\n",
    "    print('Building latents for doc {} of {}'.format(d + 1, D))\n",
    "    qtheta[d]= Empirical(tf.Variable(tf.ones([T, K]) / K))\n",
    "    latent_vars_dict[theta[d]] = qtheta[d]\n",
    "    \n",
    "    for s in range(S):\n",
    "        N = len(w_train[d][s])\n",
    "\n",
    "        qz[d][s] = Empirical(tf.Variable(tf.zeros([T, N], dtype=tf.int32)))\n",
    "        latent_vars_dict[z[d][s]] = qz[d][s]\n",
    "print()\n",
    "\n",
    "# Proposal vars\n",
    "proposal_vars_dict = {}\n",
    "\n",
    "phi_cond = [None] * S\n",
    "for s in range(S):\n",
    "    iteration_time = time.time()\n",
    "    print('Building proposals for phi {} of {}'.format(s + 1, S))\n",
    "    phi_cond[s] = ed.complete_conditional(phi[s])\n",
    "    proposal_vars_dict[phi[s]] = phi_cond[s]\n",
    "    end = time.time()\n",
    "    print('Overall time: {}, Iteration time: {}'.format(end - overall_time,\n",
    "                                                        end - iteration_time))\n",
    "\n",
    "          \n",
    "theta_cond = [None] * D\n",
    "z_cond = [[None] * S for d in range(D)]\n",
    "for d in range(D):\n",
    "    iteration_time = time.time()\n",
    "    print('Building proposals for doc {} of {}'.format(d + 1, D))\n",
    "          \n",
    "    theta_cond[d] = ed.complete_conditional(theta[d])\n",
    "    proposal_vars_dict[theta[d]] = theta_cond[d]\n",
    "    \n",
    "    for s in range(S):\n",
    "        z_cond[d][s] = ed.complete_conditional(z[d][s])\n",
    "        proposal_vars_dict[z[d][s]] = z_cond[d][s]\n",
    "        \n",
    "    end = time.time()\n",
    "    print('Overall time: {}, Iteration time: {}'.format(end - overall_time,\n",
    "                                                        end - iteration_time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Building latents for phi 1 of 3\n",
    "# Building latents for phi 2 of 3\n",
    "# Building latents for phi 3 of 3\n",
    "# Building latents for doc 1 of 50\n",
    "# Building latents for doc 2 of 50\n",
    "# Building latents for doc 3 of 50\n",
    "# Building latents for doc 4 of 50\n",
    "# Building latents for doc 5 of 50\n",
    "# Building latents for doc 6 of 50\n",
    "# Building latents for doc 7 of 50\n",
    "# Building latents for doc 8 of 50\n",
    "# Building latents for doc 9 of 50\n",
    "# Building latents for doc 10 of 50\n",
    "# Building latents for doc 11 of 50\n",
    "# Building latents for doc 12 of 50\n",
    "# Building latents for doc 13 of 50\n",
    "# Building latents for doc 14 of 50\n",
    "# Building latents for doc 15 of 50\n",
    "# Building latents for doc 16 of 50\n",
    "# Building latents for doc 17 of 50\n",
    "# Building latents for doc 18 of 50\n",
    "# Building latents for doc 19 of 50\n",
    "# Building latents for doc 20 of 50\n",
    "# Building latents for doc 21 of 50\n",
    "# Building latents for doc 22 of 50\n",
    "# Building latents for doc 23 of 50\n",
    "# Building latents for doc 24 of 50\n",
    "# Building latents for doc 25 of 50\n",
    "# Building latents for doc 26 of 50\n",
    "# Building latents for doc 27 of 50\n",
    "# Building latents for doc 28 of 50\n",
    "# Building latents for doc 29 of 50\n",
    "# Building latents for doc 30 of 50\n",
    "# Building latents for doc 31 of 50\n",
    "# Building latents for doc 32 of 50\n",
    "# Building latents for doc 33 of 50\n",
    "# Building latents for doc 34 of 50\n",
    "# Building latents for doc 35 of 50\n",
    "# Building latents for doc 36 of 50\n",
    "# Building latents for doc 37 of 50\n",
    "# Building latents for doc 38 of 50\n",
    "# Building latents for doc 39 of 50\n",
    "# Building latents for doc 40 of 50\n",
    "# Building latents for doc 41 of 50\n",
    "# Building latents for doc 42 of 50\n",
    "# Building latents for doc 43 of 50\n",
    "# Building latents for doc 44 of 50\n",
    "# Building latents for doc 45 of 50\n",
    "# Building latents for doc 46 of 50\n",
    "# Building latents for doc 47 of 50\n",
    "# Building latents for doc 48 of 50\n",
    "# Building latents for doc 49 of 50\n",
    "# Building latents for doc 50 of 50\n",
    "\n",
    "# Building proposals for phi 1 of 3\n",
    "# Overall time: 69.31266689300537, Iteration time: 54.86830019950867\n",
    "# Building proposals for phi 2 of 3\n",
    "# Overall time: 123.89829397201538, Iteration time: 54.58547306060791\n",
    "# Building proposals for phi 3 of 3\n",
    "# Overall time: 182.77833604812622, Iteration time: 58.87992310523987\n",
    "# Building proposals for doc 1 of 50\n",
    "# Overall time: 381.61259174346924, Iteration time: 198.8338508605957\n",
    "# Building proposals for doc 2 of 50\n",
    "# Overall time: 567.233188867569, Iteration time: 185.62039589881897\n",
    "# Building proposals for doc 3 of 50\n",
    "# Overall time: 771.7069668769836, Iteration time: 204.47345495224\n",
    "# Building proposals for doc 4 of 50\n",
    "# Overall time: 936.0917587280273, Iteration time: 164.38445901870728\n",
    "# Building proposals for doc 5 of 50\n",
    "# Overall time: 1120.0477230548859, Iteration time: 183.95552325248718\n",
    "# Building proposals for doc 6 of 50\n",
    "# Overall time: 1276.690170764923, Iteration time: 156.6422679424286\n",
    "# Building proposals for doc 7 of 50\n",
    "# Overall time: 1444.1476140022278, Iteration time: 167.45653009414673\n",
    "# Building proposals for doc 8 of 50\n",
    "# Overall time: 1735.4187908172607, Iteration time: 291.2701859474182\n",
    "# Building proposals for doc 9 of 50\n",
    "# Overall time: 1968.6613538265228, Iteration time: 233.24120998382568\n",
    "# Building proposals for doc 10 of 50\n",
    "# Overall time: 2185.009156703949, Iteration time: 216.34635066986084\n",
    "# Building proposals for doc 11 of 50\n",
    "# Overall time: 2463.9241259098053, Iteration time: 278.9145920276642\n",
    "# Building proposals for doc 12 of 50\n",
    "# Overall time: 2678.157154083252, Iteration time: 214.228657245636\n",
    "# Building proposals for doc 13 of 50\n",
    "# Overall time: 2890.1912257671356, Iteration time: 212.03397393226624\n",
    "# Building proposals for doc 14 of 50\n",
    "# Overall time: 3122.7205917835236, Iteration time: 232.52895283699036\n",
    "# Building proposals for doc 15 of 50\n",
    "# Overall time: 3485.069458961487, Iteration time: 362.3487198352814\n",
    "# Building proposals for doc 16 of 50\n",
    "# Overall time: 3644.913102865219, Iteration time: 159.84318804740906\n",
    "# Building proposals for doc 17 of 50\n",
    "# Overall time: 3796.687983751297, Iteration time: 151.77477407455444\n",
    "# Building proposals for doc 18 of 50\n",
    "# Overall time: 3950.3377928733826, Iteration time: 153.64937901496887\n",
    "# Building proposals for doc 19 of 50\n",
    "# Overall time: 4101.002737760544, Iteration time: 150.66468381881714\n",
    "# Building proposals for doc 20 of 50\n",
    "# Overall time: 4395.566714763641, Iteration time: 294.5638659000397\n",
    "# Building proposals for doc 21 of 50\n",
    "# Overall time: 4544.476539850235, Iteration time: 148.89263892173767\n",
    "# Building proposals for doc 22 of 50\n",
    "# Overall time: 4694.441290855408, Iteration time: 149.9646019935608\n",
    "# Building proposals for doc 23 of 50\n",
    "# Overall time: 4848.94672203064, Iteration time: 154.50405025482178\n",
    "# Building proposals for doc 24 of 50\n",
    "# Overall time: 5003.179519891739, Iteration time: 154.2320339679718\n",
    "# Building proposals for doc 25 of 50\n",
    "# Overall time: 5161.905777931213, Iteration time: 158.72613787651062\n",
    "# Building proposals for doc 26 of 50\n",
    "# Overall time: 5534.618554830551, Iteration time: 372.71096301078796\n",
    "# Building proposals for doc 27 of 50\n",
    "# Overall time: 5679.782926797867, Iteration time: 145.11774802207947\n",
    "# Building proposals for doc 28 of 50\n",
    "# Overall time: 5831.451673746109, Iteration time: 151.66864371299744\n",
    "# Building proposals for doc 29 of 50\n",
    "# Overall time: 5986.792187929153, Iteration time: 155.3397068977356\n",
    "# Building proposals for doc 30 of 50\n",
    "# Overall time: 6134.088886976242, Iteration time: 147.29659509658813\n",
    "# Building proposals for doc 31 of 50\n",
    "# Overall time: 6277.987422943115, Iteration time: 143.89844512939453\n",
    "# Building proposals for doc 32 of 50\n",
    "# Overall time: 6423.601721763611, Iteration time: 145.61409378051758\n",
    "# Building proposals for doc 33 of 50\n",
    "# Overall time: 6568.684260845184, Iteration time: 145.08171796798706\n",
    "# Building proposals for doc 34 of 50\n",
    "# Overall time: 7045.336709737778, Iteration time: 476.6523468494415\n",
    "# Building proposals for doc 35 of 50\n",
    "# Overall time: 7213.730815887451, Iteration time: 168.30789494514465\n",
    "# Building proposals for doc 36 of 50\n",
    "# Overall time: 7378.473023891449, Iteration time: 164.73943185806274\n",
    "# Building proposals for doc 37 of 50\n",
    "# Overall time: 7534.124243974686, Iteration time: 155.65112495422363\n",
    "# Building proposals for doc 38 of 50\n",
    "# Overall time: 7677.08373093605, Iteration time: 142.95938110351562\n",
    "# Building proposals for doc 39 of 50\n",
    "# Overall time: 7813.287255048752, Iteration time: 136.20341610908508\n",
    "# Building proposals for doc 40 of 50\n",
    "# Overall time: 7951.467782735825, Iteration time: 138.1804027557373\n",
    "# Building proposals for doc 41 of 50\n",
    "# Overall time: 8091.492294788361, Iteration time: 140.02440977096558\n",
    "# Building proposals for doc 42 of 50\n",
    "# Overall time: 8243.043648958206, Iteration time: 151.55125617980957\n",
    "# Building proposals for doc 43 of 50\n",
    "# Overall time: 8830.350775003433, Iteration time: 587.3069970607758\n",
    "# Building proposals for doc 44 of 50\n",
    "# Overall time: 9049.290264844894, Iteration time: 218.93365597724915\n",
    "# Building proposals for doc 45 of 50\n",
    "# Overall time: 9207.876252889633, Iteration time: 158.58503985404968\n",
    "# Building proposals for doc 46 of 50\n",
    "# Overall time: 9364.491986989975, Iteration time: 156.61562514305115\n",
    "# Building proposals for doc 47 of 50\n",
    "# Overall time: 9530.133072853088, Iteration time: 165.6409628391266\n",
    "# Building proposals for doc 48 of 50\n",
    "# Overall time: 9684.557219028473, Iteration time: 154.42402720451355\n",
    "# Building proposals for doc 49 of 50\n",
    "# Overall time: 9836.190227985382, Iteration time: 151.63291597366333\n",
    "# Building proposals for doc 50 of 50\n",
    "# Overall time: 9986.481297969818, Iteration time: 150.29096603393555"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Inference procedure w/Gibbs sampling\n",
    "inference = ed.Gibbs(latent_vars=latent_vars_dict,\n",
    "                     proposal_vars=proposal_vars_dict,\n",
    "                     data=data_dict)\n",
    "\n",
    "inference.initialize(n_iter=T, n_print=10, logdir='log')\n",
    "\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "for n in range(inference.n_iter):\n",
    "    info_dict = inference.update()\n",
    "    inference.print_progress(info_dict)\n",
    "\n",
    "inference.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.pcolormesh(qphi[1].params[-1].eval())\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var = tf.pow(qphi[1] - tf.reduce_mean(qphi[1].params, axis=0), 2)\n",
    "plt.pcolormesh(np.log(var.eval()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
